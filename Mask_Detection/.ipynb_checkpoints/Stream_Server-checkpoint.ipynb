{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported Python modules.\n",
      "Imported Python modules.\n"
     ]
    }
   ],
   "source": [
    "import imagezmq\n",
    "\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "from CentroidBasedObjectDetector import CentroidTracker\n",
    "from collections import deque\n",
    "from collections import Counter\n",
    "import imutils\n",
    "import _thread as thread\n",
    "import uuid\n",
    "from FaceDetectionModule import Face_Detector\n",
    "from FaceGazeModule import GazeEstimator\n",
    "import glob\n",
    "import uuid\n",
    "import threading\n",
    "from flask import Response\n",
    "from flask import Flask\n",
    "from flask import render_template\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: All network layers are supported.\n",
      "Input Shape: [1, 3, 300, 300]\n",
      "Output Shape: [1, 1, 200, 7]\n"
     ]
    }
   ],
   "source": [
    "maxQueueLen = 20\n",
    "developer_mode = True\n",
    "device = \"CPU\"\n",
    "cpu_extension_path = \"cpu_extension_avx2.dll\"\n",
    "detect_thresh = 0.7\n",
    "\n",
    "masked = -1\n",
    "\n",
    "model_xml = r\"Models/openvino/face-detection/FP32/face-detection-retail-0004.xml\"\n",
    "model_bin = r\"Models/openvino/face-detection/FP32/face-detection-retail-0004.bin\"\n",
    "\n",
    "plugin = Face_Detector.init_plugin(device,cpu_extension_path)\n",
    "\n",
    "faceDetector = Face_Detector()\n",
    "\n",
    "faceDetector.load_net(model_xml,model_bin,plugin)\n",
    "\n",
    "ct = CentroidTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"mask_detector_v4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image,faceDetector,thresh = 0.7):\n",
    "    result = []\n",
    "    orig = image.copy()\n",
    "    (h, w) = image.shape[:2]\n",
    "    rects,_ = faceDetector.detectFaces(image,thresh)\n",
    "        \n",
    "    objects = ct.update(rects) \n",
    "\n",
    "    for i,(startX, startY, endX, endY) in enumerate(rects):\n",
    "\n",
    "        face = image[startY:endY, startX:endX]\n",
    "        if face is None or len(face) == 0:\n",
    "            continue\n",
    "        face_crop = face.copy()\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "        face = cv2.resize(face, (224, 224))\n",
    "\n",
    "        face = img_to_array(face)\n",
    "        face = preprocess_input(face)\n",
    "        face = np.expand_dims(face, axis=0)\n",
    "\n",
    "\n",
    "        (mask, withoutMask) = model.predict(face)[0]\n",
    "\n",
    "        label = \"Mask\" if mask > withoutMask else \"No Mask\"\n",
    "\n",
    "        if i >= len(objects.keys()):\n",
    "            i = len(objects.keys()) - 1\n",
    "        rolling_ix = list(objects.keys())[i]\n",
    "        if rolling_ix in Rolling_Masks.keys():\n",
    "            Rolling_Masks[rolling_ix].append(label)\n",
    "        else:\n",
    "            Q_g = deque(maxlen = maxQueueLen)\n",
    "            Q_g.append(label)\n",
    "            Rolling_Masks[rolling_ix] = Q_g\n",
    "\n",
    "        status = Counter(Rolling_Masks[rolling_ix]).most_common(1)[0][0]\n",
    "        result.append({\"index\":rolling_ix,\"status\":status, \"img\":face_crop })\n",
    "        color = (0, 255, 0) if status == \"Mask\" else (0, 0, 255)\n",
    "        mask_status = \"Warning: NOT WEARING A PROTECTIVE MASK\"\n",
    "        if status == \"Mask\":\n",
    "            mask_status = \"Passed: Weraing a protective mask.\"\n",
    "        cv2.putText(image, mask_status, (startX, startY - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    "        cv2.rectangle(image, (startX, startY), (endX, endY), color, 4)\n",
    "\n",
    "\n",
    "    return image,result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rolling_Masks = {}\n",
    "\n",
    "img = cv2.imread(r\"C:\\Users\\ADNEC- VW 3\\Notebooks\\Mask_Detection\\dataset_raw\\new\\raw\\office\\WhatsApp Image 2020-0w6-24 at 10.15.17 AM.jpeg\")\n",
    "img,_ = process_image(img,faceDetector,thresh = 0.7)\n",
    "\n",
    "cv2.imshow(\"Video\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = imagezmq.ImageHub(open_port='tcp://*:5000')\n",
    "sender = imagezmq.ImageSender(connect_to=\"tcp://10.0.1.38:5001\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while True:\n",
    "#     (msg, frame) = server.recv_image()\n",
    "#     server.send_reply(b'OK')\n",
    "    \n",
    "#     if frame is None or len(frame) == 0:\n",
    "#         print(\"Failed to recieve stream image.\")\n",
    "#         break\n",
    "        \n",
    "#     cv2.imshow(\"Remote Stream\",frame)\n",
    "#     key = cv2.waitKey(1)\n",
    "    \n",
    "#     if key == ord(\"q\") or key == ord(\"Q\"):\n",
    "#         break\n",
    "        \n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rolling_Masks = {}\n",
    "\n",
    "while True:\n",
    "    (msg, frame) = server.recv_image()\n",
    "    server.send_reply(b'OK')\n",
    "    \n",
    "    if frame is None or len(frame) == 0:\n",
    "        print(\"Failed to recieve stream image.\")\n",
    "        break\n",
    "    try:\n",
    "        frame,_ = process_image(frame,faceDetector,thresh = 0.7)\n",
    "        sender.send_image(\"msg\",frame)\n",
    "    except:\n",
    "        sender.send_image(\"msg\",img)\n",
    "    \n",
    "    cv2.imshow(\"Remote Stream\",frame)\n",
    "    key = cv2.waitKey(1)\n",
    "\n",
    "    if key == ord(\"q\") or key == ord(\"Q\"):\n",
    "        break\n",
    "\n",
    "sender.close()\n",
    "server.close()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'OK'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sender.send_image(\"msg\",img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
