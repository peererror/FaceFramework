{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported Python modules.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import feature\n",
    "import time\n",
    "import glob\n",
    "from sklearn.metrics import accuracy_score\n",
    "from FaceDetectionModule import Face_Detector\n",
    "from FaceLandmarksModule import Landmark_Extractor\n",
    "import imutils\n",
    "import keras\n",
    "from keras.applications import ResNet50\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "resnet = ResNet50(include_top=False,weights = \"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100352,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = load_img(r\"C:\\Users\\ADNEC- VW 3\\Notebooks\\IMG_TEST\\test\\stock-photo-young-adult-woman-with-beautiful-face-clean-healthy-skin-isolated-on-white-skin-care-concept-749164501.jpg\")\n",
    "img = img_to_array(img)\n",
    "img = cv2.resize(img,(224,224))\n",
    "img = np.expand_dims(img,0)\n",
    "\n",
    "pred = resnet.predict(img)\n",
    "pred[0].flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"CPU\"\n",
    "cpu_extension_path = \"cpu_extension_avx2.dll\"\n",
    "detection_thresh = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: All network layers are supported.\n",
      "Input Shape: [1, 3, 300, 300]\n",
      "Output Shape: [1, 1, 200, 7]\n"
     ]
    }
   ],
   "source": [
    "model_xml = r\"Models/openvino/face-detection/FP16/face-detection-retail-0004.xml\"\n",
    "model_bin = r\"Models/openvino/face-detection/FP16/face-detection-retail-0004.bin\"\n",
    "\n",
    "plugin = Face_Detector.init_plugin(device,cpu_extension_path)\n",
    "\n",
    "faceDetector = Face_Detector()\n",
    "\n",
    "faceDetector.load_net(model_xml,model_bin,plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: All network layers are supported.\n",
      "Input Shape: [1, 3, 60, 60]\n",
      "Output Shape: [1, 70]\n"
     ]
    }
   ],
   "source": [
    "model_xml = r\"Models/openvino/face-landmarks/FP16/facial-landmarks-35-adas-0002.xml\"\n",
    "model_bin = r\"Models/openvino/face-landmarks/FP16/facial-landmarks-35-adas-0002.bin\"\n",
    "\n",
    "landmarkExtractor = Landmark_Extractor()\n",
    "\n",
    "landmarkExtractor.load_net(model_xml,model_bin,plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HOG:\n",
    "    def __init__(self,orientations = 9, pixelsPerCell = (8, 8),cellsPerBlock = (3, 3), transform = False):\n",
    "        self.orientations = orientations\n",
    "        self.pixelsPerCell = pixelsPerCell\n",
    "        self.cellsPerBlock = cellsPerBlock\n",
    "        self.transform = transform\n",
    "        \n",
    "    def describe(self,img):\n",
    "        hog = feature.hog(img,self.orientations,self.pixelsPerCell,self.cellsPerBlock,\n",
    "                         transform_sqrt = self.transform,block_norm=\"L2-Hys\")\n",
    "        return hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog = HOG(pixelsPerCell = (8, 8),cellsPerBlock = (3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_w = 24\n",
    "input_h = 24\n",
    "closed_dir = r\"C:\\Users\\ADNEC- VW 3\\Notebooks\\FaceRecognitionFramework\\Datasets\\dataset_B_Eye_Images\\closed\"\n",
    "open_dir = r\"C:\\Users\\ADNEC- VW 3\\Notebooks\\FaceRecognitionFramework\\Datasets\\dataset_B_Eye_Images\\open\"\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hog = HOG()\n",
    "for img_path in glob.glob(closed_dir + \"/*.jpg\"):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    vec = hog.describe(img)\n",
    "    data.append(vec)\n",
    "    labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_path in glob.glob(open_dir + \"/*.jpg\"):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img,(224,224))\n",
    "    img = np.expand_dims(img,0)\n",
    "\n",
    "    vec = resnet.predict(img)[0].flatten()\n",
    "    data.append(vec)\n",
    "    labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_path in glob.glob(closed_dir + \"/*.jpg\"):\n",
    "    img = load_img(img_path)\n",
    "    img = img_to_array(img)\n",
    "    img = cv2.resize(img,(224,224))\n",
    "    img = np.expand_dims(img,0)\n",
    "\n",
    "    vec = resnet.predict(img)[0].flatten()\n",
    "    data.append(vec)\n",
    "    labels.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hog = HOG()\n",
    "for img_path in glob.glob(open_dir + \"/*.jpg\"):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    vec = hog.describe(img)\n",
    "    data.append(vec)\n",
    "    labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(data,labels,random_state=42,test_size = 0.25,stratify = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-9dc212a6acd6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"linear\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    269\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model2= SVC(kernel = \"linear\")\n",
    "model2.fit(X_train,y_train)\n",
    "preds = model.predict(X_test)\n",
    "accuracy_score(y_test,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.966996699669967"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model= RandomForestClassifier(n_estimators=50)\n",
    "model.fit(X_train,y_train)\n",
    "preds = model.predict(X_test)\n",
    "accuracy_score(y_test,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_landmarks(img,return_img = False):\n",
    "    faces = faceDetector.detectFaces(img)\n",
    "    if faces is None or len(faces) == 0:\n",
    "        return [],[],None\n",
    "    try:\n",
    "        (x_min,y_min,x_max,y_max)= faces[0][0]\n",
    "    except:\n",
    "        return [],[],None\n",
    "    \n",
    "    img_crop = img[y_min:y_max,x_min:x_max]\n",
    "    (x_min,y_min,x_max,y_max) = (0,0,img_crop.shape[1],img_crop.shape[0])\n",
    "    img_crop = landmarkExtractor.prepare_face(img_crop)\n",
    "    \n",
    "    img = img_crop[y_min:y_max,x_min:x_max]  \n",
    "    #img = imutils.resize(img,height = 300)\n",
    "    #img = landmarkExtractor.prepare_face(img)\n",
    "    landmarks = landmarkExtractor.extractLandmarks(img)\n",
    "    landmarks = list(map(lambda x:(int(x[0]*img.shape[1]),int(x[1]*img.shape[0])),landmarks))\n",
    "    left_eye_landmarks = [landmarks[0],landmarks[1],landmarks[12],landmarks[14]]\n",
    "    right_eye_landmarks = [landmarks[2],landmarks[3],landmarks[17],landmarks[15]]\n",
    "    return right_eye_landmarks,left_eye_landmarks,img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_with_margin(img,x_min,y_min,x_max,y_max,margin_x_rate = 0.125 , margin_y_rate = 0.125):\n",
    "    margin_x = int((x_max-x_min) * margin_x_rate)\n",
    "    margin_y = int((y_max-y_min) * margin_y_rate)\n",
    "    img = img[max(y_min-margin_y,0):min(y_max+margin_y,img.shape[0]),max(x_min-margin_x-0,0):min(x_max+margin_x,img.shape[1])]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog = HOG()\n",
    "\n",
    "def eyes_status(img):\n",
    "    right_eye_landmarks,left_eye_landmarks,img = extract_landmarks(img,True)\n",
    "\n",
    "    if right_eye_landmarks == []:\n",
    "        #print(\"No Faces Found in Image\")\n",
    "        return None,None\n",
    "\n",
    "    right_eye_cnts = []\n",
    "    for lm in right_eye_landmarks:\n",
    "        right_eye_cnts.append(list(lm))\n",
    "    right_eye_cnts = np.array(right_eye_cnts,dtype=\"int32\")\n",
    "\n",
    "    left_eye_cnts = []\n",
    "    for rm in left_eye_landmarks:\n",
    "        left_eye_cnts.append(list(rm))\n",
    "    left_eye_cnts = np.array(left_eye_cnts,dtype=\"int32\")\n",
    "\n",
    "\n",
    "    hull_r = cv2.convexHull(right_eye_cnts)\n",
    "    hull_l = cv2.convexHull(left_eye_cnts)\n",
    "    (x1,y1,w1,h1) = cv2.boundingRect(hull_r)\n",
    "    (x2,y2,w2,h2)  = cv2.boundingRect(hull_l)\n",
    "\n",
    "\n",
    "    temp = img.copy()\n",
    "\n",
    "    eye_right = crop_with_margin(temp,x1,y1,x1+w1,y1+w1)\n",
    "    eye_left = crop_with_margin(temp,x2,y2,x2+w2,y2+w2)\n",
    "\n",
    "    eye_right =cv2.resize(eye_right,(224,224))\n",
    "    eye_left =cv2.resize(eye_left,(224,224))\n",
    "\n",
    "\n",
    "#cv2.rectangle(temp,(x1,y1),(x1+w1,y1+h1),(0,255,0),2)\n",
    "#cv2.rectangle(temp,(x2,y2),(x2+w2,y2+h2),(0,255,0),2)\n",
    "\n",
    "#temp = cv2.drawContours(temp,[hull_r,hull_l],-1,(255,255,0),3)\n",
    "#cv2.imshow(\"output\",temp)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "   # cv2.imshow(\"output\",eye_right)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "\n",
    "    #cv2.imshow(\"output\",eye_left)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "\n",
    "    #vec_r = hog.describe(eye_right)\n",
    "    #vec_l = hog.describe(eye_left)\n",
    "    \n",
    "    vec_r  = resnet.predict(np.expand_dims(eye_right,0))[0].flatten()\n",
    "    vec_l  = resnet.predict(np.expand_dims(eye_left,0))[0].flatten()\n",
    "    print(vec_r.shape)\n",
    "    open_r = model.predict([vec_r])\n",
    "    open_l = model.predict([vec_l])\n",
    "\n",
    "#    if open_r == 0:\n",
    "       # print(\"Right Eye is Closed\")\n",
    " #   else:\n",
    "  #      print(\"Right Eye is Open\")\n",
    "    \n",
    "   # if open_l == 0:\n",
    "    #    print(\"Left Eye is Closed\")\n",
    "    #else:\n",
    "     #   print(\"Left Eye is Open\")\n",
    "    return open_r,open_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100352,)\n",
      "(100352,)\n",
      "(100352,)\n",
      "(100352,)\n",
      "(100352,)\n",
      "(100352,)\n",
      "(100352,)\n",
      "(100352,)\n",
      "(100352,)\n",
      "(100352,)\n",
      "(100352,)\n",
      "(100352,)\n",
      "(100352,)\n",
      "(100352,)\n",
      "(100352,)\n",
      "(100352,)\n",
      "(100352,)\n",
      "(100352,)\n",
      "(100352,)\n",
      "(100352,)\n",
      "(100352,)\n",
      "(100352,)\n",
      "(100352,)\n",
      "(100352,)\n",
      "(100352,)\n",
      "(100352,)\n",
      "(100352,)\n",
      "(100352,)\n",
      "(100352,)\n",
      "(100352,)\n"
     ]
    }
   ],
   "source": [
    "fint_color = (255,0,255)\n",
    "\n",
    "for img_path in glob.glob(r\"C:\\Users\\ADNEC- VW 3\\Notebooks\\IMG_TEST\\test\\*.*\"):\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None or len(img) == 0:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        img = imutils.resize(img,width=1920)\n",
    "        open_r,open_l  = eyes_status(img)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    if open_r is not None:\n",
    "        if open_r == 0:\n",
    "            cv2.putText(img,\"Right Eye Closed\",(100,100),cv2.FONT_HERSHEY_SIMPLEX,2,fint_color,2)\n",
    "        else:\n",
    "            cv2.putText(img,\"Right Eye Open\",(100,100),cv2.FONT_HERSHEY_SIMPLEX,2,fint_color,2)\n",
    "            \n",
    "        if open_l == 0:\n",
    "            cv2.putText(img,\"Left Eye Closed\",(100,200),cv2.FONT_HERSHEY_SIMPLEX,2,fint_color,2)\n",
    "        else:\n",
    "            cv2.putText(img,\"Left Eye Open\",(100,200),cv2.FONT_HERSHEY_SIMPLEX,2,fint_color,2)\n",
    "    img = imutils.resize(img,width = 1000)\n",
    "    cv2.imshow(\"Output\",img)   \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(0)\n",
    "video.set(cv2.CAP_PROP_FRAME_WIDTH,800)\n",
    "video.set(cv2.CAP_PROP_FRAME_HEIGHT,600)\n",
    "\n",
    "while True:\n",
    "    ret,frame = video.read()\n",
    "    if ret == False or frame is None:\n",
    "        continue\n",
    "    open_r,open_l = eyes_status(frame)\n",
    "    if open_r is not None:\n",
    "        if open_r == 0:\n",
    "            cv2.putText(frame,\"Right Eye Closed\",(100,100),cv2.FONT_HERSHEY_SIMPLEX,2,(255,255,0),1)\n",
    "        else:\n",
    "            cv2.putText(frame,\"Right Eye Open\",(100,100),cv2.FONT_HERSHEY_SIMPLEX,2,(255,255,0),1)\n",
    "            \n",
    "        if open_l == 0:\n",
    "            cv2.putText(frame,\"Left Eye Closed\",(100,200),cv2.FONT_HERSHEY_SIMPLEX,2,(255,255,0),1)\n",
    "        else:\n",
    "            cv2.putText(frame,\"Left Eye Open\",(100,200),cv2.FONT_HERSHEY_SIMPLEX,2,(255,255,0),1)\n",
    "    cv2.imshow(\"Video\",frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
