{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported Python modules.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PersonSegmentationModule import Person_Segmentor\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "#import pycocotools.mask as mask_util\n",
    "\n",
    "#from .blob import to_numpy\n",
    "from boxes import expand_boxes\n",
    "\n",
    "\n",
    "def postprocess_batch(batch_ids, scores, classes, boxes, raw_cls_masks,\n",
    "                      batch_size, im_h, im_w, im_scale_y=None, im_scale_x=None, im_scale=None,\n",
    "                      full_image_masks=True, encode_masks=False,\n",
    "                      confidence_threshold=0.0):\n",
    "    boxes_all = [np.empty((0, 4), dtype=np.float32) for _ in range(batch_size)]\n",
    "    scores_all = [np.empty((0, ), dtype=np.float32) for _ in range(batch_size)]\n",
    "    classes_all = [np.empty((0, ), dtype=np.float32) for _ in range(batch_size)]\n",
    "    raw_masks_all = [None for _ in range(batch_size)]\n",
    "    masks_all = [[] for _ in range(batch_size)]\n",
    "\n",
    "    if batch_ids is None:\n",
    "        return scores_all, classes_all, boxes_all, masks_all\n",
    "\n",
    "    scale_x = im_scale_x\n",
    "    scale_y = im_scale_y\n",
    "    if im_scale is not None:\n",
    "        scale_x = im_scale\n",
    "        scale_y = im_scale\n",
    "    assert len(scale_x) == len(scale_y)\n",
    "\n",
    "  #  batch_ids = to_numpy(batch_ids)\n",
    "\n",
    "    num_objs_per_batch = []\n",
    "    for i in range(batch_size):\n",
    "        num_objs_per_batch.append(np.count_nonzero(batch_ids == i))\n",
    "\n",
    "    begin = 0\n",
    "    for i in range(0, len(num_objs_per_batch)):\n",
    "        end = begin + num_objs_per_batch[i]\n",
    "        # Scale boxes back to the original image\n",
    "        boxes_all[i] = boxes[begin:end]\n",
    "        scores_all[i] = scores[begin:end]\n",
    "        classes_all[i] = classes[begin:end]\n",
    "        raw_masks_all[i] = raw_cls_masks[begin:end]\n",
    "        begin = end\n",
    "\n",
    "    # Resize segmentation masks to fit corresponding bounding boxes.\n",
    "    for i in range(batch_size):\n",
    "        scores_all[i], classes_all[i], boxes_all[i], masks_all[i] = \\\n",
    "            postprocess(scores_all[i], classes_all[i], boxes_all[i], raw_masks_all[i],\n",
    "                        im_h[i], im_w[i], scale_y[i], scale_x[i], None,\n",
    "                        full_image_masks, encode_masks,\n",
    "                        confidence_threshold)\n",
    "\n",
    "    return scores_all, classes_all, boxes_all, masks_all\n",
    "\n",
    "\n",
    "def postprocess(scores, classes, boxes, raw_cls_masks,\n",
    "                im_h, im_w, im_scale_y=None, im_scale_x=None, im_scale=None,\n",
    "                full_image_masks=True, encode_masks=False,\n",
    "                confidence_threshold=0.0):\n",
    "    no_detections = (np.empty((0, ), dtype=np.float32), np.empty((0, ), dtype=np.float32),\\\n",
    "                     np.empty((0, 4), dtype=np.float32), [])\n",
    "    if scores is None:\n",
    "        return no_detections\n",
    "\n",
    "    scale = im_scale\n",
    "    if scale is None:\n",
    "        assert (im_scale_x is not None) and (im_scale_y is not None)\n",
    "        scale = [im_scale_x, im_scale_y, im_scale_x, im_scale_y]\n",
    "\n",
    "  #  scores = to_numpy(scores)\n",
    "  #1 classes = to_numpy(classes)\n",
    "    #boxes = to_numpy(boxes)\n",
    "  #  raw_cls_masks = to_numpy(raw_cls_masks)\n",
    "\n",
    "    confidence_filter = scores > confidence_threshold\n",
    "    scores = scores[confidence_filter]\n",
    "    classes = classes[confidence_filter]\n",
    "    boxes = boxes[confidence_filter]\n",
    "    raw_cls_masks = list(segm for segm, is_valid in zip(raw_cls_masks, confidence_filter) if is_valid)\n",
    "\n",
    "    if len(scores) == 0:\n",
    "        return no_detections\n",
    "\n",
    "    boxes = boxes / scale\n",
    "    classes = classes.astype(np.uint32)\n",
    "    masks = []\n",
    "    for box, cls, raw_mask in zip(boxes, classes, raw_cls_masks):\n",
    "        raw_cls_mask = raw_mask[cls, ...]\n",
    "        mask = segm_postprocess(box, raw_cls_mask, im_h, im_w, full_image_masks, encode_masks)\n",
    "        masks.append(mask)\n",
    "\n",
    "    return scores, classes, boxes, masks\n",
    "\n",
    "\n",
    "def segm_postprocess(box, raw_cls_mask, im_h, im_w, full_image_mask=True, encode=False):\n",
    "    # Add zero border to prevent upsampling artifacts on segment borders.\n",
    "    raw_cls_mask = np.pad(raw_cls_mask, ((1, 1), (1, 1)), 'constant', constant_values=0)\n",
    "    extended_box = expand_boxes(box[np.newaxis, :],\n",
    "                                raw_cls_mask.shape[0] / (raw_cls_mask.shape[0] - 2.0))[0]\n",
    "    extended_box = extended_box.astype(int)\n",
    "    w, h = np.maximum(extended_box[2:] - extended_box[:2] + 1, 1)\n",
    "    x0, y0 = np.clip(extended_box[:2], a_min=0, a_max=[im_w, im_h])\n",
    "    x1, y1 = np.clip(extended_box[2:] + 1, a_min=0, a_max=[im_w, im_h])\n",
    "\n",
    "    raw_cls_mask = cv2.resize(raw_cls_mask, (w, h)) > 0.5\n",
    "    mask = raw_cls_mask.astype(np.uint8)\n",
    "\n",
    "    if full_image_mask:\n",
    "        # Put an object mask in an image mask.\n",
    "        im_mask = np.zeros((im_h, im_w), dtype=np.uint8)\n",
    "        im_mask[y0:y1, x0:x1] = mask[(y0 - extended_box[1]):(y1 - extended_box[1]),\n",
    "                                     (x0 - extended_box[0]):(x1 - extended_box[0])]\n",
    "    else:\n",
    "        original_box = box.astype(int)\n",
    "        x0, y0 = np.clip(original_box[:2], a_min=0, a_max=[im_w, im_h])\n",
    "        x1, y1 = np.clip(original_box[2:] + 1, a_min=0, a_max=[im_w, im_h])\n",
    "        im_mask = np.ascontiguousarray(mask[(y0 - original_box[1]):(y1 - original_box[1]),\n",
    "                                            (x0 - original_box[0]):(x1 - original_box[0])])\n",
    "\n",
    "    if encode:\n",
    "        im_mask = mask_util.encode(np.array(im_mask[:, :, np.newaxis].astype(np.uint8), order='F'))[0]\n",
    "        im_mask['counts'] = im_mask['counts'].decode('utf-8')\n",
    "\n",
    "    return im_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Visualizer(object):\n",
    "\n",
    "    def __init__(self, class_labels, confidence_threshold=0.5, show_boxes=False,\n",
    "                 show_masks=True, show_scores=False):\n",
    "        super().__init__()\n",
    "        self.class_labels = class_labels\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.class_color_palette = np.asarray([2 ** 25 - 1, 2 ** 15 - 1, 2 ** 21 - 1])\n",
    "        self.instance_color_palette = self.color_palette\n",
    "        self.show_masks = show_masks\n",
    "        self.show_boxes = show_boxes\n",
    "        self.show_scores = show_scores\n",
    "\n",
    "    def __call__(self, image, boxes, classes, scores, segms=None, ids=None):\n",
    "        result = image.copy()\n",
    "\n",
    "        # Filter out detections with low confidence.\n",
    "        filter_mask = scores > self.confidence_threshold\n",
    "        scores = scores[filter_mask]\n",
    "        classes = classes[filter_mask]\n",
    "        boxes = boxes[filter_mask]\n",
    "\n",
    "        if self.show_masks and segms is not None:\n",
    "            segms = list(segm for segm, show in zip(segms, filter_mask) if show)\n",
    "            result = self.overlay_masks(result, segms, classes, ids)\n",
    "\n",
    "        if self.show_boxes:\n",
    "            result = self.overlay_boxes(result, boxes, classes)\n",
    "\n",
    "        result = self.overlay_class_names(result, boxes, classes, scores,\n",
    "                                          show_score=self.show_scores)\n",
    "        return result\n",
    "\n",
    "    def compute_colors_for_labels(self, labels):\n",
    "        colors = labels[:, None] * self.class_color_palette\n",
    "        colors = (colors % 255).astype(np.uint8)\n",
    "        return colors\n",
    "\n",
    "    def overlay_boxes(self, image, boxes, classes):\n",
    "        colors = self.compute_colors_for_labels(classes).tolist()\n",
    "        for box, color in zip(boxes, colors):\n",
    "            box = box.astype(int)\n",
    "            top_left, bottom_right = box[:2].tolist(), box[2:].tolist()\n",
    "            image = cv2.rectangle(\n",
    "                image, tuple(top_left), tuple(bottom_right), tuple(color), 1\n",
    "            )\n",
    "        return image\n",
    "\n",
    "    def overlay_masks(self, image, masks, classes, ids=None):\n",
    "        colors = self.compute_colors_for_labels(classes).tolist()\n",
    "\n",
    "        segments_image = image.copy()\n",
    "        aggregated_mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "        aggregated_colored_mask = np.zeros(image.shape, dtype=np.uint8)\n",
    "        black = np.zeros(3, dtype=np.uint8)\n",
    "\n",
    "        for i, (mask, color) in enumerate(zip(masks, colors)):\n",
    "            mask = mask.astype(np.uint8)\n",
    "            color_idx = i if ids is None else ids[i]\n",
    "            mask_color = (255,255,255)\n",
    "            \n",
    "            cv2.bitwise_or(aggregated_mask, mask, dst=aggregated_mask)\n",
    "            cv2.bitwise_or(aggregated_colored_mask, np.asarray(mask_color, dtype=np.uint8),\n",
    "                           dst=aggregated_colored_mask, mask=mask)\n",
    "            \n",
    "        # Fill the area occupied by all instances with a colored instances mask image.\n",
    "        #cv2.bitwise_and(segments_image, black, dst=segments_image, mask=aggregated_mask)\n",
    "        #cv2.bitwise_or(segments_image, aggregated_colored_mask, dst=segments_image, mask=aggregated_mask)\n",
    "        # Blend original image with the one, where instances are colored.\n",
    "        # As a result instances masks become transparent.\n",
    "        #cv2.addWeighted(image, 0.5, segments_image, 0.5, 0, dst=image)\n",
    "        #cv2.bi\n",
    "     #   aggregated_colored_mask = cv2.GaussianBlur(aggregated_colored_mask,(51,51),0)\n",
    "       # kernelSize = (11,11)\n",
    "        #kernel = cv2.getStructuringElement(cv2.MORPH_RECT,kernelSize)\n",
    "        #aggregated_colored_mask = cv2.morphologyEx(aggregated_colored_mask,cv2.MORPH_CLOSE,kernel)\n",
    "        #aggregated_colored_mask = cv2.blur(aggregated_colored_mask,(51,51))\n",
    "       # segments_image = 255 * segments_image/aggregated_colored_mask\n",
    "        return cv2.bitwise_and(aggregated_colored_mask,segments_image), aggregated_colored_mask\n",
    "\n",
    "    def overlay_class_names(self, image, boxes, classes, scores, show_score=True):\n",
    "        labels = [self.class_labels[i] for i in classes]\n",
    "        template = '{}: {:.2f}' if show_score else '{}'\n",
    "        white = (255, 255, 255)\n",
    "\n",
    "        for box, score, label in zip(boxes, scores, labels):\n",
    "            s = template.format(label, score)\n",
    "            textsize = cv2.getTextSize(s, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]\n",
    "            position = ((box[:2] + box[2:] - textsize) / 2).astype(int)\n",
    "            cv2.putText(image, s, tuple(position), cv2.FONT_HERSHEY_SIMPLEX, .5, white, 1)\n",
    "\n",
    "        return image\n",
    "\n",
    "    color_palette = np.array([[0, 113, 188],\n",
    "                              [216, 82, 24],\n",
    "                              [236, 176, 31],\n",
    "                              [125, 46, 141],\n",
    "                              [118, 171, 47],\n",
    "                              [76, 189, 237],\n",
    "                              [161, 19, 46],\n",
    "                              [76, 76, 76],\n",
    "                              [153, 153, 153],\n",
    "                              [255, 0, 0],\n",
    "                              [255, 127, 0],\n",
    "                              [190, 190, 0],\n",
    "                              [0, 255, 0],\n",
    "                              [0, 0, 255],\n",
    "                              [170, 0, 255],\n",
    "                              [84, 84, 0],\n",
    "                              [84, 170, 0],\n",
    "                              [84, 255, 0],\n",
    "                              [170, 84, 0],\n",
    "                              [170, 170, 0],\n",
    "                              [170, 255, 0],\n",
    "                              [255, 84, 0],\n",
    "                              [255, 170, 0],\n",
    "                              [255, 255, 0],\n",
    "                              [0, 84, 127],\n",
    "                              [0, 170, 127],\n",
    "                              [0, 255, 127],\n",
    "                              [84, 0, 127],\n",
    "                              [84, 84, 127],\n",
    "                              [84, 170, 127],\n",
    "                              [84, 255, 127],\n",
    "                              [170, 0, 127],\n",
    "                              [170, 84, 127],\n",
    "                              [170, 170, 127],\n",
    "                              [170, 255, 127],\n",
    "                              [255, 0, 127],\n",
    "                              [255, 84, 127],\n",
    "                              [255, 170, 127],\n",
    "                              [255, 255, 127],\n",
    "                              [0, 84, 255],\n",
    "                              [0, 170, 255],\n",
    "                              [0, 255, 255],\n",
    "                              [84, 0, 255],\n",
    "                              [84, 84, 255],\n",
    "                              [84, 170, 255],\n",
    "                              [84, 255, 255],\n",
    "                              [170, 0, 255],\n",
    "                              [170, 84, 255],\n",
    "                              [170, 170, 255],\n",
    "                              [170, 255, 255],\n",
    "                              [255, 0, 255],\n",
    "                              [255, 84, 255],\n",
    "                              [255, 170, 255],\n",
    "                              [42, 0, 0],\n",
    "                              [84, 0, 0],\n",
    "                              [127, 0, 0],\n",
    "                              [170, 0, 0],\n",
    "                              [212, 0, 0],\n",
    "                              [255, 0, 0],\n",
    "                              [0, 42, 0],\n",
    "                              [0, 84, 0],\n",
    "                              [0, 127, 0],\n",
    "                              [0, 170, 0],\n",
    "                              [0, 212, 0],\n",
    "                              [0, 255, 0],\n",
    "                              [0, 0, 42],\n",
    "                              [0, 0, 84],\n",
    "                              [0, 0, 127],\n",
    "                              [0, 0, 170],\n",
    "                              [0, 0, 212],\n",
    "                              [0, 0, 255],\n",
    "                              [0, 0, 0],\n",
    "                              [36, 36, 36],\n",
    "                              [72, 72, 72],\n",
    "                              [109, 109, 109],\n",
    "                              [145, 145, 145],\n",
    "                              [182, 182, 182],\n",
    "                              [218, 218, 218],\n",
    "                              [255, 255, 255]], dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = Person_Segmentor()\n",
    "\n",
    "plugin = Person_Segmentor.init_plugin(\"CPU\",\"cpu_extension_avx2.dll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: All network layers are supported.\n",
      "Input Data Shape: [1, 3, 480, 480]\n",
      "Input Info Shape: [1, 3]\n",
      "Output Shape: [100, 4]\n"
     ]
    }
   ],
   "source": [
    "model_xml = r\"D:\\OPENVINO\\person-segmentation\\FP16\\instance-segmentation-security-0050.xml\"\n",
    "model_bin = r\"D:\\OPENVINO\\person-segmentation\\FP16\\instance-segmentation-security-0050.bin\"\n",
    "\n",
    "seg.load_net(model_xml,model_bin,plugin,num_requests=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seg = Person_Segmentor()\n",
    "plugin = Person_Segmentor.init_plugin(\"CPU\",\"cpu_extension_avx2.dll\")\n",
    "viz = Visualizer(None)\n",
    "\n",
    "def segment_image(img):\n",
    "\n",
    "    img=cv2.resize(img,(400,400))\n",
    "   #img = cv2.GaussianBlur(img,(3,3),0)\n",
    "    result = seg.segment(img)\n",
    "   \n",
    "    scores, classes, boxes, masks = postprocess(result[\"scores\"],result[\"classes\"],result[\"boxes\"],result[\"raw_masks\"],400,400,im_scale=1.2)\n",
    "    if (1 in classes) == False:\n",
    "        return img,None,False\n",
    "    else:\n",
    "        classes = np.array([1])\n",
    "        \n",
    "  \n",
    "    viz_img,mask = viz.overlay_masks(img,masks,classes)\n",
    "    person = False\n",
    "    if len(classes)>0 and classes[0] == 1:\n",
    "        person = True\n",
    "    return viz_img,mask,person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = cv2.imread(r\"C:\\Users\\ADNEC- VW 3\\Pictures\\adventure_arid_background_desert_desolate_dry_dunes_600264.jpg\")\n",
    "bg = cv2.resize(bg,(1920,1080))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "viz = Visualizer(None)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH,1920)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH,1080)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    person = False\n",
    "    # Our operations on the frame come here\n",
    "    try:\n",
    "        frame,mask,person = segment_image(frame)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    if person:\n",
    "        #foreground = cv2.resize(frame,(800,600))\n",
    "        #background = cv2.bitwise_or(cv2.resize(mask,(800,600)),bg)\n",
    "        final = cv2.bitwise_and(frame,mask)\n",
    "        final = cv2.resize(final,(1920,1080))\n",
    "        mask = cv2.resize(mask,(1920,1080))\n",
    "        #foreground = cv2.bitwise_or(bg,mask)\n",
    "        background = bg.copy()\n",
    "        background[mask == 255] = 0\n",
    "        #rgb_bg_masked[rgb_hand_mask == 0] = [0,0,0]\n",
    "       # final = cv2.addWeighted(final,0.7,cv2.GaussianBlur(final,(51,51),0),-0.1,0)\n",
    "        #cv2.addWeighted(final, 0.9, background, 0.5, 0, dst=final)\n",
    "        final_blurred = cv2.GaussianBlur(final,(51,51),0)\n",
    "        final = cv2.addWeighted(final,0.8,final_blurred,0.2,0)\n",
    "        cv2.imshow('frame',cv2.add(final ,background))\n",
    "    else:\n",
    "        cv2.imshow('frame',cv2.resize(frame,(1920,1080)))\n",
    "                    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3., 3., 1.],\n",
       "       [3., 3., 1.],\n",
       "       [3., 3., 1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = np.ones((3,3))\n",
    "\n",
    "m[:,0:2] = 3\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-257de47f043b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mviz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVisualizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshow_scores\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mviz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moverlay_boxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"boxes\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"classes\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Image\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "labels = [\"Person\"]\n",
    "for i in range(1,100):\n",
    "    labels.append(\"N/A\")\n",
    "\n",
    "viz = Visualizer(labels,show_scores= True)\n",
    "im = viz.overlay_boxes(img,result[\"boxes\"],result[\"classes\"])\n",
    "\n",
    "cv2.imshow(\"Image\",im)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"classes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "(min_x,min_y,max_x,max_y) = result[\"boxes\"][0]\n",
    "\n",
    "cv2.rectangle(img,(min_x,min_y),(max_x,max_y),(255,255,0),3)\n",
    "\n",
    "cv2.imshow(\"Image\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 81, 14, 14)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"raw_masks\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-ef32ae28cb3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmasked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"uint8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawContours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmasked\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"raw_masks\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "masked = np.zeros((400,400),dtype = \"uint8\")\n",
    "cv2.drawContours(masked,result[\"raw_masks\"][0][0],-1,(255,255,255),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"classes\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
